// src/pages/Interview.tsx
import { useState, useEffect, useRef } from 'react'
import { useNavigate, useLocation } from 'react-router-dom'
import InterviewHUD from '../components/interview/InterviewHUD'
import CameraView from '../components/interview/CameraView'
import ChatPanel from '../components/interview/ChatPanel'
import ControlBar from '../components/interview/ControlBar'
import { ALL_QUESTIONS } from '../data/questionBank'
import { API_BASE_URL } from '../lib/api'

// ğŸ”Š STT ìƒíƒœ íƒ€ì…
type SttState = 'idle' | 'starting' | 'recording' | 'transcribing'

// QuestionBankì—ì„œ ë„˜ì–´ì˜¤ëŠ” state íƒ€ì…
type InterviewLocationState = {
  mode?: 'practice_set'
  setId?: string
  setTitle?: string
  setIcon?: string
  questionIds?: string[] // PRACTICE_SETS ì•ˆì˜ questions ë°°ì—´
}

// ì±„íŒ… ë©”ì‹œì§€ íƒ€ì…
type Message = {
  type: 'ai' | 'user'
  content: string
  timestamp: Date
}

// ğŸ“Œ Reportë¡œ ë„˜ê¸¸ ë‹µë³€ ì•„ì´í…œ íƒ€ì…
type AnswerForReport = {
  questionNumber: number
  question: string
  answer: string
  score?: number

  // ğŸ”¥ ì˜ìƒ ê´€ë ¨
  duration?: string          // "2ë¶„ 30ì´ˆ" ê°™ì€ í‘œì‹œìš©
  durationSeconds?: number   // ì´ˆ ë‹¨ìœ„ (í•©ì‚°ìš©)
  videoUrl?: string
  videoBlob?: Blob
}

// ì´ˆ â†’ "Xë¶„ Yì´ˆ" í¬ë§·
const formatDurationKo = (seconds: number): string => {
  const total = Math.floor(seconds)
  const m = Math.floor(total / 60)
  const s = total % 60

  if (m > 0) {
    return s > 0 ? `${m}ë¶„ ${s}ì´ˆ` : `${m}ë¶„`
  }
  return `${s}ì´ˆ`
}

export default function Interview() {
  const navigate = useNavigate()
  const location = useLocation()
  const state = (location.state || {}) as InterviewLocationState

  // ğŸ”¹ ë„˜ì–´ì˜¨ questionIds ê¸°ì¤€ìœ¼ë¡œ ì§ˆë¬¸ ë°°ì—´ êµ¬ì„±
  const questionsFromSet =
    state.questionIds && state.questionIds.length > 0
      ? ALL_QUESTIONS.filter((q) => state.questionIds!.includes(q.id))
      : ALL_QUESTIONS.slice(0, 8) // í˜¹ì‹œ ì—†ìœ¼ë©´ ê¸°ë³¸ 8ê°œ ì‚¬ìš©

  // ì‹¤ì œ ì¸í„°ë·°ì—ì„œ ì‚¬ìš©í•  ì§ˆë¬¸ë“¤
  const [questions] = useState(questionsFromSet)
  const [totalQuestions] = useState(questionsFromSet.length || 1)

  // ğŸ”¥ ì•„ì§ ì§ˆë¬¸ ì‹œì‘ ì „ â†’ -1
  // 0ë¶€í„°ëŠ” Q1, Q2, ... ì˜ë¯¸
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(-1)

  // âœ… í•­ìƒ ìµœì‹  ì¸ë±ìŠ¤ë¥¼ ì°¸ì¡°í•˜ê¸° ìœ„í•œ ref
  const currentQuestionRef = useRef(-1)
  useEffect(() => {
    currentQuestionRef.current = currentQuestionIndex
  }, [currentQuestionIndex])

  const [isRecording, setIsRecording] = useState(true)
  const [cameraEnabled, setCameraEnabled] = useState(true)
  const [micEnabled, setMicEnabled] = useState(true)
  const [elapsedTime, setElapsedTime] = useState(0)

  // âœ… ëª¨ë“  ì§ˆë¬¸ì´ ëë‚¬ëŠ”ì§€ ì—¬ë¶€
  const [isFinished, setIsFinished] = useState(false)

  // âœ… Reportë¡œ ë„˜ê¸¸ "ì§ˆë¬¸ + ë‹µë³€" ëª©ë¡
  const [answersForReport, setAnswersForReport] = useState<AnswerForReport[]>([])

  // ğŸ”¥ ì´ˆê¸° ë©”ì‹œì§€ëŠ” ì¸ì‚¬ë§Œ
  const [messages, setMessages] = useState<Message[]>([
    {
      type: 'ai',
      content: 'ì•ˆë…•í•˜ì„¸ìš”! ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì¤€ë¹„ë˜ì…¨ë‚˜ìš”?',
      timestamp: new Date()
    }
  ])

  // ğŸ¤ STT ê´€ë ¨ ìƒíƒœ
  const [voiceText, setVoiceText] = useState('')
  const [sttState, setSttState] = useState<SttState>('idle')

  // âœ… ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ & MediaRecorder ê´€ë¦¬
  const streamRef = useRef<MediaStream | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)

  // CameraViewì—ì„œ ìŠ¤íŠ¸ë¦¼ ì „ë‹¬
  const handleStreamReady = (stream: MediaStream | null) => {
    streamRef.current = stream
  }

  // ğŸ”¥ ì§ˆë¬¸ë³„ ì˜ìƒ ë…¹í™” ì‹œì‘
  const startRecordingForQuestion = (questionNumber: number) => {
    const stream = streamRef.current
    if (!stream) {
      console.warn('ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì—†ìŒ, ë…¹í™” ì‹œì‘ ë¶ˆê°€')
      return
    }

    // í˜¹ì‹œ ì´ì „ ë…¹í™”ê°€ ì‚´ì•„ìˆìœ¼ë©´ ì •ë¦¬
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop()
    }

    const chunks: BlobPart[] = []
    const recorder = new MediaRecorder(stream)

    recorder.ondataavailable = (e) => {
      if (e.data && e.data.size > 0) {
        chunks.push(e.data)
      }
    }

    recorder.onstop = () => {
      if (chunks.length === 0) return

      const blob = new Blob(chunks, { type: 'video/webm' })
      const videoUrl = URL.createObjectURL(blob)

      // ğŸ”¥ ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì½ì–´ì„œ ê¸¸ì´ ê³„ì‚°
      const tempVideo = document.createElement('video')
      tempVideo.preload = 'metadata'
      tempVideo.src = videoUrl

      tempVideo.onloadedmetadata = () => {
        const durationSec = tempVideo.duration || 0
        const durationLabel = formatDurationKo(durationSec)

        setAnswersForReport((prev) => {
          const existingIndex = prev.findIndex(
            (item) => item.questionNumber === questionNumber
          )

          if (existingIndex >= 0) {
            const updated = [...prev]
            updated[existingIndex] = {
              ...updated[existingIndex],
              videoUrl,
              videoBlob: blob,
              duration: durationLabel,
              durationSeconds: durationSec
            }
            return updated
          }

          const q = questions[questionNumber - 1]
          return [
            ...prev,
            {
              questionNumber,
              question: q?.text ?? '',
              answer: '',
              videoUrl,
              videoBlob: blob,
              duration: durationLabel,
              durationSeconds: durationSec
            }
          ]
        })
      }
    }

    mediaRecorderRef.current = recorder
    recorder.start()
    console.log(`â–¶ï¸ Q${questionNumber} ë…¹í™” ì‹œì‘`)
  }

  // ğŸ”¥ í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ë…¹í™” ì¢…ë£Œ
  const stopRecordingForCurrentQuestion = () => {
    const recorder = mediaRecorderRef.current
    if (recorder && recorder.state === 'recording') {
      recorder.stop()
      console.log('â¹ ë…¹í™” ì¢…ë£Œ')
    }
  }

  // Timer
  useEffect(() => {
    if (isRecording) {
      const interval = setInterval(() => {
        setElapsedTime((prev) => prev + 1)
      }, 1000)
      return () => clearInterval(interval)
    }
  }, [isRecording])

  // âœ… ëª¨ë“  ì§ˆë¬¸ ëë‚˜ë©´ ìë™ìœ¼ë¡œ ë¦¬í¬íŠ¸ í˜ì´ì§€ë¡œ ì´ë™
  useEffect(() => {
    if (isFinished) {
      const timer = setTimeout(() => {
        navigate('/report/1/loading', {
          state: {
            answers: answersForReport
          }
        })
      }, 2000) // "ëª¨ë“  ì§ˆë¬¸ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤." ë©˜íŠ¸ ë³´ì—¬ì¤„ ì‹œê°„

      return () => clearTimeout(timer)
    }
  }, [isFinished, navigate, answersForReport])

  // ğŸ”¥ ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€ ë³´ëƒˆì„ ë•Œ
  const handleSendMessage = (message: string) => {
    // 1) ì±„íŒ…ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    setMessages((prev) => [
      ...prev,
      {
        type: 'user',
        content: message,
        timestamp: new Date()
      }
    ])

    // âœ… í•­ìƒ ìµœì‹  ì§ˆë¬¸ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©
    const idx = currentQuestionRef.current

    // 2) í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì§ˆë¬¸ì— ëŒ€í•œ "ë‹µë³€ ê¸°ë¡" ì €ì¥
    if (idx >= 0 && idx < questions.length) {
      const q = questions[idx]

      setAnswersForReport((prev) => {
        const questionNumber = idx + 1
        const existingIndex = prev.findIndex(
          (item) => item.questionNumber === questionNumber
        )

        // ê°™ì€ ì§ˆë¬¸ì— ì—¬ëŸ¬ ë²ˆ ë‹µí•˜ë©´ â†’ ë‹µë³€ì„ ì´ì–´ë¶™ì´ê¸°
        if (existingIndex >= 0) {
          const updated = [...prev]
          const prevAnswer = updated[existingIndex].answer
          updated[existingIndex] = {
            ...updated[existingIndex],
            answer: prevAnswer ? `${prevAnswer}\n${message}` : message
          }
          return updated
        }

        // ì²˜ìŒ ë‹µí•˜ëŠ” ì§ˆë¬¸ì´ë©´ ìƒˆë¡œ ì¶”ê°€
        return [
          ...prev,
          {
            questionNumber,
            question: q.text,
            answer: message,
            score: undefined,
            duration: undefined,
            durationSeconds: undefined
          }
        ]
      })
    }

    // 3) AI ì‘ë‹µ + ì§ˆë¬¸ ì§„í–‰ (+ ë…¹í™” ì œì–´)
    setTimeout(() => {
      setCurrentQuestionIndex((prevIdx) => {
        // âœ… ì•„ì§ ì§ˆë¬¸ ì‹œì‘ ì „ (-1) â†’ ì²« ë²ˆì§¸ ì§ˆë¬¸ ë˜ì§€ê¸°
        if (prevIdx < 0) {
          if (questions.length === 0) {
            const firstContent = 'ì§ˆë¬¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            setMessages((prev) => {
              const last = prev[prev.length - 1]
              if (last && last.type === 'ai' && last.content === firstContent) {
                return prev
              }
              return [
                ...prev,
                {
                  type: 'ai',
                  content: firstContent,
                  timestamp: new Date()
                }
              ]
            })
            return -1
          }

          const firstContent = `ì¢‹ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì§ˆë¬¸ì…ë‹ˆë‹¤.\n${questions[0].text}`

          setMessages((prev) => {
            const last = prev[prev.length - 1]
            if (last && last.type === 'ai' && last.content === firstContent) {
              return prev
            }
            return [
              ...prev,
              {
                type: 'ai',
                content: firstContent,
                timestamp: new Date()
              }
            ]
          })

          // ğŸ”¥ Q1 ì˜ìƒ ë…¹í™” ì‹œì‘
          startRecordingForQuestion(1)

          // ì´ì œë¶€í„°ëŠ” 0ë²ˆ ì¸ë±ìŠ¤ = Q1
          return 0
        }

        // âœ… ì´ë¯¸ ì§ˆë¬¸ ì§„í–‰ ì¤‘ â†’ ë‹¤ìŒ ì§ˆë¬¸ ë¡œì§
        const isLastQuestion = prevIdx >= questions.length - 1

        // ğŸ”¥ í˜„ì¬ ì§ˆë¬¸ ë…¹í™” ì¢…ë£Œ
        stopRecordingForCurrentQuestion()

        const nextIdx = isLastQuestion ? prevIdx : prevIdx + 1

        const nextContent = isLastQuestion
          ? 'ì¢‹ì€ ë‹µë³€ ì˜ ë“¤ì—ˆìŠµë‹ˆë‹¤. ëª¨ë“  ì§ˆë¬¸ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
          : `ë„¤, ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤.\n${questions[nextIdx].text}`

        // ì¤‘ë³µ AI ë©˜íŠ¸ ë°©ì§€
        setMessages((prev) => {
          const last = prev[prev.length - 1]
          if (last && last.type === 'ai' && last.content === nextContent) {
            return prev
          }

          return [
            ...prev,
            {
              type: 'ai',
              content: nextContent,
              timestamp: new Date()
            }
          ]
        })

        // âœ… ë§ˆì§€ë§‰ ì§ˆë¬¸ì´ë©´ ì¸í„°ë·° ì¢…ë£Œ í”Œë˜ê·¸ ON â†’ ë¦¬í¬íŠ¸ë¡œ ì´ë™
        if (isLastQuestion) {
          setIsFinished(true)
          return prevIdx
        }

        // ğŸ”¥ ë‹¤ìŒ ì§ˆë¬¸(Q{nextIdx+1})ë¶€í„° ìƒˆë¡œ ë…¹í™” ì‹œì‘
        const nextQuestionNumber = nextIdx + 1
        startRecordingForQuestion(nextQuestionNumber)

        return nextIdx
      })
    }, 1500)
  }

  const handleEndInterview = () => {
    if (window.confirm('ë©´ì ‘ì„ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?')) {
      // ì§„í–‰ ì¤‘ì¸ ì§ˆë¬¸ ë…¹í™” ì¢…ë£Œ
      stopRecordingForCurrentQuestion()
      navigate('/report/1/loading', {
        state: {
          answers: answersForReport
        }
      })
    }
  }

  const handleToggleCamera = () => {
    setCameraEnabled((prev) => !prev)
  }

  const handleToggleMic = () => {
    setMicEnabled((prev) => !prev)
  }

  // ğŸ¤ "ìŒì„±ìœ¼ë¡œ ë‹µë³€í•˜ê¸° / ìŒì„± ë‹µë³€ ì¤‘ì§€" ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬
  const handleVoiceClick = async () => {
    try {
      if (sttState === 'idle') {
        setVoiceText('')
        setSttState('starting')

        const startRequest = fetch(`${API_BASE_URL}/stt/start`, {
          method: 'POST'
        })
        const delay = new Promise((resolve) => setTimeout(resolve, 1000))

        const [res] = await Promise.all([startRequest, delay])

        if (!res.ok) {
          throw new Error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨')
        }

        setSttState('recording')
      } else if (sttState === 'recording') {
        setSttState('transcribing')

        const res = await fetch(`${API_BASE_URL}/stt/stop`, {
          method: 'POST'
        })

        if (!res.ok) {
          throw new Error('ë…¹ìŒ/ì¸ì‹ ì‹¤íŒ¨')
        }

        const data = await res.json()
        console.log('STT result:', data)

        if (data.text) {
          // ì…ë ¥ì°½ì— ë¿Œë¦¬ëŠ” ê±´ ê·¸ëŒ€ë¡œ ìœ ì§€
          setVoiceText(data.text)
          // í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ handleSendMessage(data.text)ë„ í˜¸ì¶œ ê°€ëŠ¥
        } else {
          alert('ì¸ì‹ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.')
        }

        setSttState('idle')
      } else {
        return
      }
    } catch (err) {
      console.error(err)
      alert('ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
      setSttState('idle')
    }
  }

  return (
    <div
      style={{
        height: '100vh',
        display: 'grid',
        gridTemplateColumns: '1fr 400px',
        background: 'var(--bg-dark)',
        overflow: 'hidden'
      }}
    >
      {/* Left Side - Camera */}
      <div
        style={{
          background: 'var(--bg-dark)',
          position: 'relative',
          display: 'flex',
          flexDirection: 'column'
        }}
      >
        {/* Top Bar */}
        <InterviewHUD
          isRecording={isRecording}
          elapsedTime={elapsedTime}
          // ğŸ”¥ ì•„ì§ ì§ˆë¬¸ ì „ì´ë©´ 0 / N ìœ¼ë¡œ ë³´ì´ê²Œ
          currentQuestion={
            currentQuestionIndex < 0
              ? 0
              : Math.min(currentQuestionIndex + 1, totalQuestions)
          }
          totalQuestions={totalQuestions}
        />

        {/* Camera View */}
        <div
          style={{
            flex: 1,
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'center',
            position: 'relative',
            background:
              'linear-gradient(135deg, rgba(31, 60, 136, 0.3), rgba(44, 77, 247, 0.3))'
          }}
        >
          <CameraView
            isRecording={isRecording}
            cameraEnabled={cameraEnabled}
            micEnabled={micEnabled}
            onStreamReady={handleStreamReady}
          />
        </div>

        {/* Bottom Control Bar */}
        <ControlBar
          isRecording={isRecording}
          cameraEnabled={cameraEnabled}
          micEnabled={micEnabled}
          onToggleRecording={() => setIsRecording(!isRecording)}
          onToggleCamera={handleToggleCamera}
          onToggleMic={handleToggleMic}
          onEndInterview={handleEndInterview}
        />

        {(sttState === 'starting' || sttState === 'recording') && (
          <div
            style={{
              padding: '0.75rem 1rem',
              color: 'white',
              fontSize: '0.9rem'
            }}
          >
            {sttState === 'starting'
              ? 'â³ ë§ˆì´í¬ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...'
              : 'ğŸ™ ìŒì„± ë‹µë³€ ë…¹ìŒ ì¤‘...'}
          </div>
        )}
      </div>

      {/* Right Side - Chat Panel */}
      <div
        style={{
          height: '100vh',
          overflow: 'hidden',
          display: 'flex',
          flexDirection: 'column'
        }}
      >
        <ChatPanel
          messages={messages}
          onSendMessage={handleSendMessage}
          disabled={false}
          onVoiceClick={handleVoiceClick}
          voiceText={voiceText}
          sttState={sttState}
        />
      </div>
    </div>
  )
}