// src/pages/Interview.tsx
import { useState, useEffect, useRef } from 'react'
import { useNavigate, useLocation } from 'react-router-dom'
import InterviewHUD from '../components/interview/InterviewHUD'
import CameraView from '../components/interview/CameraView'
import ChatPanel from '../components/interview/ChatPanel'
import ControlBar from '../components/interview/ControlBar'
import { ALL_QUESTIONS } from '../data/questionBank'
import { API_BASE_URL } from '../lib/utils'

// ğŸ“Š STT ìƒíƒœ íƒ€ì…
type SttState = 'idle' | 'starting' | 'recording' | 'transcribing'

// QuestionBankì—ì„œ ë„˜ì–´ì˜¤ëŠ” state íƒ€ì…
type InterviewLocationState = {
  mode?: 'practice_set'
  setId?: string
  setTitle?: string
  setIcon?: string
  questionIds?: string[] // PRACTICE_SETS ì•ˆì˜ questions ë°°ì—´
}

// ì±„íŒ… ë©”ì‹œì§€ íƒ€ì…
type Message = {
  type: 'ai' | 'user'
  content: string
  timestamp: Date
}

// ğŸ“Œ Reportë¡œ ë„˜ê¸¸ ë‹µë³€ ì•„ì´í…œ íƒ€ì…
type AnswerForReport = {
  questionNumber: number
  question: string
  answer: string
  score?: number

  // ğŸ”¥ ì˜ìƒ ê´€ë ¨
  duration?: string          // "2ë¶„ 30ì´ˆ" ê°™ì€ í‘œì‹œìš©
  durationSeconds?: number   // ì´ˆ ë‹¨ìœ„ (í•©ì‚°ìš©)
  videoUrl?: string
  videoBlob?: Blob
}

// ì´ˆ â†’ "Xë¶„ Yì´ˆ" í¬ë§·
const formatDurationKo = (seconds: number): string => {
  const total = Math.floor(seconds)
  const m = Math.floor(total / 60)
  const s = total % 60

  if (m > 0) {
    return s > 0 ? `${m}ë¶„ ${s}ì´ˆ` : `${m}ë¶„`
  }
  return `${s}ì´ˆ`
}

export default function Interview() {
  const navigate = useNavigate()
  const location = useLocation()
  const state = (location.state || {}) as InterviewLocationState

  // ğŸ”¹ ë„˜ì–´ì˜¨ questionIds ê¸°ì¤€ìœ¼ë¡œ ì§ˆë¬¸ ë°°ì—´ êµ¬ì„±
  const questionsFromSet =
    state.questionIds && state.questionIds.length > 0
      ? ALL_QUESTIONS.filter((q) => state.questionIds!.includes(q.id))
      : ALL_QUESTIONS.slice(0, 8) // í˜¹ì‹œ ì—†ìœ¼ë©´ ê¸°ë³¸ 8ê°œ ì‚¬ìš©

  // ì‹¤ì œ ì¸í„°ë·°ì—ì„œ ì‚¬ìš©í•  ì§ˆë¬¸ë“¤
  const [questions] = useState(questionsFromSet)
  const [totalQuestions] = useState(questionsFromSet.length || 1)

  // ğŸ”¥ ì•„ì§ ì§ˆë¬¸ ì‹œì‘ ì „ â†’ -1
  // 0ë¶€í„°ëŠ” Q1, Q2, ... ì˜ë¯¸
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(-1)

  // âœ… í•­ìƒ ìµœì‹  ì¸ë±ìŠ¤ë¥¼ ì°¸ì¡°í•˜ê¸° ìœ„í•œ ref
  const currentQuestionRef = useRef(-1)
  useEffect(() => {
    currentQuestionRef.current = currentQuestionIndex
  }, [currentQuestionIndex])

  const [isRecording, setIsRecording] = useState(true)
  const [cameraEnabled, setCameraEnabled] = useState(true)
  const [micEnabled, setMicEnabled] = useState(true)
  const [elapsedTime, setElapsedTime] = useState(0)

  // âœ… ëª¨ë“  ì§ˆë¬¸ì´ ëë‚¬ëŠ”ì§€ ì—¬ë¶€
  const [isFinished, setIsFinished] = useState(false)

  // âœ… Reportë¡œ ë„˜ê¸¸ "ì§ˆë¬¸ + ë‹µë³€" ëª©ë¡
  const [answersForReport, setAnswersForReport] = useState<AnswerForReport[]>([])

  // ğŸ”¥ ì´ˆê¸° ë©”ì‹œì§€ëŠ” ì¸ì‚¬ë§Œ
  const [messages, setMessages] = useState<Message[]>([
    {
      type: 'ai',
      content: 'ì•ˆë…•í•˜ì„¸ìš”! ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì¤€ë¹„ë˜ì…¨ë‚˜ìš”?',
      timestamp: new Date()
    }
  ])

  // ğŸ¤ STT ê´€ë ¨ ìƒíƒœ
  const [voiceText, setVoiceText] = useState('')
  const [sttState, setSttState] = useState<SttState>('idle')

  // âœ… ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ & MediaRecorder ê´€ë¦¬ (ë¹„ë””ì˜¤ìš©)
  const streamRef = useRef<MediaStream | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)

  // ğŸ¤ STTìš© ì˜¤ë””ì˜¤ MediaRecorder
  const audioRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])

  // CameraViewì—ì„œ ìŠ¤íŠ¸ë¦¼ ì „ë‹¬
  const handleStreamReady = (stream: MediaStream | null) => {
    streamRef.current = stream
  }

  // ğŸ”¥ ì§ˆë¬¸ë³„ ì˜ìƒ ë…¹í™” ì‹œì‘
  const startRecordingForQuestion = (questionNumber: number) => {
    const stream = streamRef.current
    if (!stream) {
      console.warn('ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì—†ìŒ, ë…¹í™” ì‹œì‘ ë¶ˆê°€')
      return
    }

    // í˜¹ì‹œ ì´ì „ ë…¹í™”ê°€ ì‚´ì•„ìˆìœ¼ë©´ ì •ë¦¬
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop()
    }

    const chunks: BlobPart[] = []
    const recorder = new MediaRecorder(stream)

    recorder.ondataavailable = (e) => {
      if (e.data && e.data.size > 0) {
        chunks.push(e.data)
      }
    }

    recorder.onstop = () => {
      if (chunks.length === 0) return

      const blob = new Blob(chunks, { type: 'video/webm' })
      const videoUrl = URL.createObjectURL(blob)

      // ğŸ”¥ ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì½ì–´ì„œ ê¸¸ì´ ê³„ì‚°
      const tempVideo = document.createElement('video')
      tempVideo.preload = 'metadata'
      tempVideo.src = videoUrl

      tempVideo.onloadedmetadata = () => {
        const durationSec = tempVideo.duration || 0
        const durationLabel = formatDurationKo(durationSec)

        setAnswersForReport((prev) => {
          const existingIndex = prev.findIndex(
            (item) => item.questionNumber === questionNumber
          )

          if (existingIndex >= 0) {
            const updated = [...prev]
            updated[existingIndex] = {
              ...updated[existingIndex],
              videoUrl,
              videoBlob: blob,
              duration: durationLabel,
              durationSeconds: durationSec
            }
            return updated
          }

          const q = questions[questionNumber - 1]
          return [
            ...prev,
            {
              questionNumber,
              question: q?.text ?? '',
              answer: '',
              videoUrl,
              videoBlob: blob,
              duration: durationLabel,
              durationSeconds: durationSec
            }
          ]
        })
      }
    }

    mediaRecorderRef.current = recorder
    recorder.start()
    console.log(`â–¶ï¸ Q${questionNumber} ë…¹í™” ì‹œì‘`)
  }

  // ğŸ›‘ í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì§ˆë¬¸ì˜ ë…¹í™” ì¢…ë£Œ
  const stopRecordingForCurrentQuestion = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop()
      console.log('â¹ ë…¹í™” ì¢…ë£Œ')
    }
  }

  // ğŸ”¥ ë§¤ ì´ˆë§ˆë‹¤ elapsedTime ì—…ë°ì´íŠ¸
  useEffect(() => {
    if (!isRecording) return

    const timer = setInterval(() => {
      setElapsedTime((prev) => prev + 1)
    }, 1000)

    return () => clearInterval(timer)
  }, [isRecording])

  // ğŸ”¥ ì¸í„°ë·° ì¢…ë£Œ ê°ì§€ â†’ ë¦¬í¬íŠ¸ë¡œ ì´ë™
  useEffect(() => {
    if (isFinished) {
      const timer = setTimeout(() => {
        stopRecordingForCurrentQuestion()

        navigate('/report/1/loading', {
          state: {
            answers: answersForReport
          }
        })
      }, 2000)

      return () => clearTimeout(timer)
    }
  }, [isFinished, answersForReport, navigate])

  // ğŸ”¥ ì‚¬ìš©ìê°€ ë©”ì‹œì§€ ì „ì†¡í•˜ë©´
  const handleSendMessage = (content: string) => {
    if (!content.trim()) return

    // 1) ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    setMessages((prev) => [
      ...prev,
      { type: 'user', content, timestamp: new Date() }
    ])

    // 2) í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì§ˆë¬¸ì´ ìˆë‹¤ë©´, answer ì—…ë°ì´íŠ¸
    const currentIdx = currentQuestionRef.current
    if (currentIdx >= 0) {
      const questionNumber = currentIdx + 1
      setAnswersForReport((prev) => {
        const existingIndex = prev.findIndex(
          (item) => item.questionNumber === questionNumber
        )

        if (existingIndex >= 0) {
          const updated = [...prev]
          updated[existingIndex] = {
            ...updated[existingIndex],
            answer: content
          }
          return updated
        }

        const q = questions[currentIdx]
        return [
          ...prev,
          {
            questionNumber,
            question: q?.text ?? '',
            answer: content
          }
        ]
      })

      // ğŸ›‘ ë‹µë³€ ì™„ë£Œ â†’ ë…¹í™” ì¤‘ì§€
      stopRecordingForCurrentQuestion()
    }

    // 3) ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° (1.5ì´ˆ í›„)
    setTimeout(() => {
      setCurrentQuestionIndex((prevIdx) => {
        const nextIdx = prevIdx + 1
        const isLastQuestion = nextIdx >= questions.length

        const nextContent = isLastQuestion
          ? 'ì¢‹ì€ ë‹µë³€ ì˜ ë“¤ì—ˆìŠµë‹ˆë‹¤. ëª¨ë“  ì§ˆë¬¸ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
          : `ë„¤, ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤.\n${questions[nextIdx].text}`

        // ì¤‘ë³µ AI ë©˜íŠ¸ ë°©ì§€
        setMessages((prev) => {
          const last = prev[prev.length - 1]
          if (last && last.type === 'ai' && last.content === nextContent) {
            return prev
          }

          return [
            ...prev,
            {
              type: 'ai',
              content: nextContent,
              timestamp: new Date()
            }
          ]
        })

        // âœ… ë§ˆì§€ë§‰ ì§ˆë¬¸ì´ë©´ ì¸í„°ë·° ì¢…ë£Œ í”Œë˜ê·¸ ON â†’ ë¦¬í¬íŠ¸ë¡œ ì´ë™
        if (isLastQuestion) {
          setIsFinished(true)
          return prevIdx
        }

        // ğŸ”¥ ë‹¤ìŒ ì§ˆë¬¸(Q{nextIdx+1})ë¶€í„° ìƒˆë¡œ ë…¹í™” ì‹œì‘
        const nextQuestionNumber = nextIdx + 1
        startRecordingForQuestion(nextQuestionNumber)

        return nextIdx
      })
    }, 1500)
  }

  const handleEndInterview = () => {
    if (window.confirm('ë©´ì ‘ì„ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?')) {
      // ì§„í–‰ ì¤‘ì¸ ì§ˆë¬¸ ë…¹í™” ì¢…ë£Œ
      stopRecordingForCurrentQuestion()
      navigate('/report/1/loading', {
        state: {
          answers: answersForReport
        }
      })
    }
  }

  const handleToggleCamera = () => {
    setCameraEnabled((prev) => !prev)
  }

  const handleToggleMic = () => {
    setMicEnabled((prev) => !prev)
  }

  // ğŸ¤ "ìŒì„±ìœ¼ë¡œ ë‹µë³€í•˜ê¸° / ìŒì„± ë‹µë³€ ì¤‘ì§€" ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬
  const handleVoiceClick = async () => {
    try {
      if (sttState === 'idle') {
        // ===== 1ë‹¨ê³„: ë…¹ìŒ ì‹œì‘ =====
        setVoiceText('')
        setSttState('starting')

        // ë°±ì—”ë“œì— ë…¹ìŒ ì‹œì‘ ì•Œë¦¼
        const startRequest = fetch(`${API_BASE_URL}/stt/start`, {
          method: 'POST'
        })
        const delay = new Promise((resolve) => setTimeout(resolve, 1000))

        const [res] = await Promise.all([startRequest, delay])

        if (!res.ok) {
          throw new Error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨')
        }

        // âœ… ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘
        const stream = streamRef.current
        if (!stream) {
          alert('ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
          setSttState('idle')
          return
        }

        // ì˜¤ë””ì˜¤ íŠ¸ë™ë§Œ ì‚¬ìš© (ë¹„ë””ì˜¤ ì œì™¸)
        const audioStream = new MediaStream(stream.getAudioTracks())
        const audioRecorder = new MediaRecorder(audioStream, {
          mimeType: 'audio/webm'
        })

        audioChunksRef.current = []

        audioRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) {
            audioChunksRef.current.push(e.data)
          }
        }

        audioRecorder.start()
        audioRecorderRef.current = audioRecorder

        console.log('ğŸ¤ ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘')
        setSttState('recording')

      } else if (sttState === 'recording') {
        // ===== 2ë‹¨ê³„: ë…¹ìŒ ì¢…ë£Œ ë° STT ìš”ì²­ =====
        setSttState('transcribing')

        // ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ì§€
        const audioRecorder = audioRecorderRef.current
        if (!audioRecorder) {
          throw new Error('ì˜¤ë””ì˜¤ ë ˆì½”ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        }

        // ë…¹ìŒ ì¤‘ì§€ í›„ ë°ì´í„° ìˆ˜ì§‘
        audioRecorder.stop()

        // ondataavailableì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        await new Promise<void>((resolve) => {
          audioRecorder.onstop = () => {
            console.log('ğŸ¤ ì˜¤ë””ì˜¤ ë…¹ìŒ ì¢…ë£Œ')
            resolve()
          }
        })

        // ë…¹ìŒëœ ì˜¤ë””ì˜¤ Blob ìƒì„±
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        console.log('ğŸ“¦ ì˜¤ë””ì˜¤ Blob í¬ê¸°:', audioBlob.size, 'bytes')

        // FormDataë¡œ ë°±ì—”ë“œì— ì „ì†¡
        const formData = new FormData()
        formData.append('audio', audioBlob, 'recording.webm')

        const res = await fetch(`${API_BASE_URL}/stt/stop`, {
          method: 'POST',
          body: formData
        })

        if (!res.ok) {
          const errorText = await res.text()
          throw new Error(`ë…¹ìŒ/ì¸ì‹ ì‹¤íŒ¨: ${errorText}`)
        }

        const data = await res.json()
        console.log('STT result:', data)

        if (data.text) {
          // ì…ë ¥ì°½ì— ë¿Œë¦¬ëŠ” ê±´ ê·¸ëŒ€ë¡œ ìœ ì§€
          setVoiceText(data.text)
          // í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ handleSendMessage(data.text)ë„ í˜¸ì¶œ ê°€ëŠ¥
        } else {
          alert('ì¸ì‹ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.')
        }

        setSttState('idle')
      } else {
        return
      }
    } catch (err) {
      console.error('STT ì˜¤ë¥˜:', err)
      alert('ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
      setSttState('idle')
    }
  }

  return (
    <div
      style={{
        height: '100vh',
        display: 'grid',
        gridTemplateColumns: '1fr 400px',
        background: 'var(--bg-dark)',
        overflow: 'hidden'
      }}
    >
      {/* Left Side - Camera */}
      <div
        style={{
          background: 'var(--bg-dark)',
          position: 'relative',
          display: 'flex',
          flexDirection: 'column'
        }}
      >
        {/* Top Bar */}
        <InterviewHUD
          isRecording={isRecording}
          elapsedTime={elapsedTime}
          // ğŸ”¥ ì•„ì§ ì§ˆë¬¸ ì „ì´ë©´ 0 / N ìœ¼ë¡œ ë³´ì´ê²Œ
          currentQuestion={
            currentQuestionIndex < 0
              ? 0
              : Math.min(currentQuestionIndex + 1, totalQuestions)
          }
          totalQuestions={totalQuestions}
        />

        {/* Camera View */}
        <div
          style={{
            flex: 1,
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'center',
            position: 'relative',
            background:
              'linear-gradient(135deg, rgba(31, 60, 136, 0.3), rgba(44, 77, 247, 0.3))'
          }}
        >
          <CameraView
            isRecording={isRecording}
            cameraEnabled={cameraEnabled}
            micEnabled={micEnabled}
            onStreamReady={handleStreamReady}
          />
        </div>

        {/* Bottom Control Bar */}
        <ControlBar
          isRecording={isRecording}
          cameraEnabled={cameraEnabled}
          micEnabled={micEnabled}
          onToggleRecording={() => setIsRecording(!isRecording)}
          onToggleCamera={handleToggleCamera}
          onToggleMic={handleToggleMic}
          onEndInterview={handleEndInterview}
        />

        {(sttState === 'starting' || sttState === 'recording') && (
          <div
            style={{
              padding: '0.75rem 1rem',
              color: 'white',
              fontSize: '0.9rem'
            }}
          >
            {sttState === 'starting'
              ? 'â³ ë§ˆì´í¬ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...'
              : 'ğŸ™ ìŒì„± ë‹µë³€ ë…¹ìŒ ì¤‘...'}
          </div>
        )}
      </div>

      {/* Right Side - Chat Panel */}
      <div
        style={{
          height: '100vh',
          overflow: 'hidden',
          display: 'flex',
          flexDirection: 'column'
        }}
      >
        <ChatPanel
          messages={messages}
          onSendMessage={handleSendMessage}
          disabled={false}
          onVoiceClick={handleVoiceClick}
          voiceText={voiceText}
          sttState={sttState}
        />
      </div>
    </div>
  )
}