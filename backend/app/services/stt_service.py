# backend\app\services\stt_service.py
import os
os.environ["HF_HUB_DISABLE_SYMLINKS"] = "1"
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

import threading
import numpy as np
import sounddevice as sd
from faster_whisper import WhisperModel

MODEL_SIZE = "base"

print("[Whisper ëª¨ë¸ ë¡œë“œ ì¤‘...]")
model = WhisperModel(
    MODEL_SIZE,
    device="cpu",
    compute_type="int8"
)
print("[Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ]\n")

SAMPLE_RATE = 16000
CHANNELS = 1
MIN_AUDIO_SECONDS = 1.0

buffer = np.zeros((0, CHANNELS), dtype=np.float32)
buffer_lock = threading.Lock()

stream: sd.InputStream | None = None  # Python 3.10 ì´ìƒ


def audio_callback(indata, frames, t, status):
    global buffer
    if status:
        print(f"[ì˜¤ë””ì˜¤ ìƒíƒœ] {status}", flush=True)
    with buffer_lock:
        buffer = np.concatenate([buffer, indata.copy()], axis=0)


def transcribe_once(audio: np.ndarray) -> str:
    if audio.ndim > 1:
        audio = audio.reshape(-1)
    segments, info = model.transcribe(
        audio,
        language="ko",
        beam_size=5,
        vad_filter=True,
    )
    text = "".join(seg.text for seg in segments).strip()
    return text


def start_recording():
    """ë§ˆì´í¬ ë…¹ìŒ ì‹œì‘ (ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ë©´ ë¬´ì‹œ)"""
    global buffer, stream

    if stream is not None:
        print("[STT] ì´ë¯¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤.")
        return

    buffer = np.zeros((0, CHANNELS), dtype=np.float32)

    print("ğŸ™ ë…¹ìŒ ì‹œì‘")

    stream = sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        callback=audio_callback,
        dtype="float32"
    )
    stream.start()


def stop_and_transcribe() -> str:
    """í˜„ì¬ê¹Œì§€ ë…¹ìŒëœ ë²„í¼ë¡œ STT ìˆ˜í–‰ í›„ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    global buffer, stream

    if stream is None:
        print("[STT] ë…¹ìŒì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return ""

    stream.stop()
    stream.close()
    stream = None
    print("ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ")

    with buffer_lock:
        audio = buffer.copy()
        buffer = np.zeros((0, CHANNELS), dtype=np.float32)

    num_samples = len(audio)
    if num_samples < MIN_AUDIO_SECONDS * SAMPLE_RATE:
        print("â— ë§í•œ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŒ")
        return ""

    print(f"[ì¸ì‹ ì¤‘... ì•½ {num_samples / SAMPLE_RATE:.1f}ì´ˆ ë¶„ëŸ‰]")
    text = transcribe_once(audio)
    print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {text}")
    return text
