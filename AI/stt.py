# AI\stt.py
import os
os.environ["HF_HUB_DISABLE_SYMLINKS"] = "1"
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

import threading
import numpy as np
import sounddevice as sd
from faster_whisper import WhisperModel

# ===========================
# 1) Whisper ëª¨ë¸ ë¡œë“œ
# ===========================

MODEL_SIZE = "base"

print("[ëª¨ë¸ ë¡œë“œ ì¤‘...]")
model = WhisperModel(
    MODEL_SIZE,
    device="cpu",        # GPU ìˆìœ¼ë©´ "cuda"
    compute_type="int8"  # CPUì—ì„œ ì†ë„/ì •í™•ë„ ì ˆì¶©
)
print("[ëª¨ë¸ ë¡œë“œ ì™„ë£Œ]\n")

# ===========================
# 2) ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
# ===========================

SAMPLE_RATE = 16000
CHANNELS = 1
MIN_AUDIO_SECONDS = 1.0  # ìµœì†Œ ì´ ì •ë„ëŠ” ë§í•´ì•¼ ì¸ì‹

# ë§ˆì´í¬ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ì˜¤ë””ì˜¤ë¥¼ ìŒ“ì•„ë‘˜ ë²„í¼ & ë½
buffer = np.zeros((0, CHANNELS), dtype=np.float32)
buffer_lock = threading.Lock()


def audio_callback(indata, frames, t, status):
    """ë§ˆì´í¬ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ì˜¤ë””ì˜¤ë¥¼ ê³„ì† bufferì— ìŒ“ëŠ” ì½œë°±"""
    global buffer
    if status:
        print(f"[ì˜¤ë””ì˜¤ ìƒíƒœ] {status}", flush=True)
    with buffer_lock:
        buffer = np.concatenate([buffer, indata.copy()], axis=0)


# ===========================
# 3) ì¸ì‹ í•¨ìˆ˜
# ===========================

def transcribe_once(audio: np.ndarray) -> str:
    """ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— Whisperì— ë„£ì–´ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if audio.ndim > 1:
        audio = audio.reshape(-1)  # (samples, 1) -> (samples,)
    segments, info = model.transcribe(
        audio,
        language="ko",   # í•œêµ­ì–´
        beam_size=5,     # beam ëŠ˜ë¦´ìˆ˜ë¡ ì •í™•ë„â†‘, ì†ë„â†“
        vad_filter=True  # ì•ë’¤ ë¬µìŒ ì œê±°
    )
    text = "".join(seg.text for seg in segments).strip()
    return text


# ===========================
# 4) ë©”ì¸ (í•œ ë²ˆ ì¸ì‹ í›„ ì¢…ë£Œ)
# ===========================

def main():
    global buffer

    print("=== Whisper ë…¹ìŒ ëª¨ë“œ ===")

    # InputStream ì•ˆì—ì„œ input()ìœ¼ë¡œ ì—”í„°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ë™ì•ˆ ê³„ì† ë…¹ìŒë¨
    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        callback=audio_callback,
        dtype="float32"
    ):
        input("â–¶ ë…¹ìŒ ì‹œì‘ (ì—”í„° ì‹œ ì¢…ë£Œ) : ")

        # ì—”í„° ëˆŒë¦° ì‹œì ê¹Œì§€ì˜ ì˜¤ë””ì˜¤ë¥¼ ë³µì‚¬
        with buffer_lock:
            audio = buffer.copy()

    # ì—¬ê¸° ë„ë‹¬í•˜ë©´ InputStream ì»¨í…ìŠ¤íŠ¸ë¥¼ ë²—ì–´ë‚¬ìœ¼ë¯€ë¡œ ë…¹ìŒì€ ì´ë¯¸ ì¢…ë£Œë¨

    num_samples = len(audio)
    if num_samples < MIN_AUDIO_SECONDS * SAMPLE_RATE:
        print("\nâ— ì¸ì‹í•  ë§Œí¼ ì¶©ë¶„íˆ ë§í•˜ì§€ ì•Šì•˜ê±°ë‚˜, ë…¹ìŒì´ ê±°ì˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        print("í”„ë¡œê·¸ë¨ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì„œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        return

    print(f"\n[ì¸ì‹ ì¤‘... ì•½ {num_samples / SAMPLE_RATE:.1f}ì´ˆ ë¶„ëŸ‰]\n")
    text = transcribe_once(audio)

    if text:
        print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {text}\n")
    else:
        print("â— ì¸ì‹ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n[ê°•ì œ ì¢…ë£Œ]")
